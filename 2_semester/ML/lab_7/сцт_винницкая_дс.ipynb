{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "hsbyb4tyki9nx32utdtjpk",
    "id": "71AQJg3CDMn9"
   },
   "source": [
    "# Deep learning для классификации картинок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Семинар состоит из 2 частей\n",
    "\n",
    "1. Ознакомьтесь со структурой обычного обучающего скрипта и потренируйте старую добрую сеть, подобную vgg\n",
    "2. Улучшите качество с помощью сети, подобной resnet\n",
    "\n",
    "Но сначала посмотрим на данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./vgg-neural-network-architecture.png\" alt=\"Drawing\" style=\"width:90%\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "34l2kkk7t84llsmzyxus1",
    "id": "2MaELIpIDMoA"
   },
   "source": [
    "# Tiny ImageNet dataset\n",
    "На этом семинаре мы сосредоточимся на задаче распознавания изображений на Tiny Image Net dataset. Этот набор данных содержит\n",
    "* 100 тысяч изображений размером 3x64x64\n",
    "* 200 различных классов: змеи, пауки, кошки, грузовики, кузнечики, чайки и т.д.\n",
    "\n",
    "На самом деле, это подмножество набора данных ImageNet с изображениями, уменьшенными в 4 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rjwf5t0s4f8zbnfmyu7q",
    "id": "swKtJaVyDMoU"
   },
   "source": [
    "## Image examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "nbxuu26h8hhcgzzgeh5nh",
    "id": "h5wImXEaDMoV"
   },
   "source": [
    "\n",
    "\n",
    "<tr>\n",
    "    <td> <img src=\"https://github.com/yandexdataschool/Practical_DL/blob/sem3spring2019/week03_convnets/tinyim3.png?raw=1\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "    <td> <img src=\"https://github.com/yandexdataschool/Practical_DL/blob/sem3spring2019/week03_convnets/tinyim2.png?raw=1\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "w71ngep3y8jm2s3xt0qg",
    "id": "Do-qRQp8DMoW"
   },
   "source": [
    "<tr>\n",
    "    <td> <img src=\"https://github.com/yandexdataschool/Practical_DL/blob/sem3spring2019/week03_convnets/tiniim.png?raw=1\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:15.634264Z",
     "iopub.status.busy": "2025-06-02T00:05:15.633932Z",
     "iopub.status.idle": "2025-06-02T00:05:15.642719Z",
     "shell.execute_reply": "2025-06-02T00:05:15.642199Z",
     "shell.execute_reply.started": "2025-06-02T00:05:15.634230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "def download_tinyImg200(path,\n",
    "                        url='http://cs231n.stanford.edu/tiny-imagenet-200.zip',\n",
    "                        tarname='tiny-imagenet-200.zip'):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    output_name = os.path.join(path, tarname)\n",
    "    if os.path.exists(output_name):\n",
    "        print(\"Dataset was already downloaded to '{}'. Skip downloading\".format(output_name))\n",
    "    else:\n",
    "        urlretrieve(url, output_name)\n",
    "        print(\"Dataset was downloaded to '{}'\".format(output_name))\n",
    "\n",
    "    print(\"Extract downloaded dataset to '{}'\".format(path))\n",
    "    with zipfile.ZipFile(output_name, 'r') as f:\n",
    "        f.extractall(path=path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "5nh892g5zpl9qv5fki8vpk",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:15.644070Z",
     "iopub.status.busy": "2025-06-02T00:05:15.643821Z",
     "iopub.status.idle": "2025-06-02T00:05:34.361730Z",
     "shell.execute_reply": "2025-06-02T00:05:34.361141Z",
     "shell.execute_reply.started": "2025-06-02T00:05:15.644055Z"
    },
    "id": "5rQhiYyRDMoG",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was already downloaded to '.\\tiny-imagenet-200.zip'. Skip downloading\n",
      "Extract downloaded dataset to '.'\n"
     ]
    }
   ],
   "source": [
    "data_path = '.'\n",
    "download_tinyImg200(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Training script structure and vgg-like network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы обучить нейронную сеть, надо решить 5 задач:\n",
    "1. data loader (data provider) - как загружать и дополнять данные для обучения nn\n",
    "2. neural network architecture - что будет обучаться\n",
    "3. loss function (+ auxilary metrics on train and validation set) - как проверить качество нейронной сети\n",
    "4. optiimzer and training schedule - как будет обучаться нейронная сеть\n",
    "5. \"Train loop\" - что именно нужно делать для каждого пакета, как часто проверять ошибку проверки, как часто сохранять сеть и т.д. Этот код можно было бы написать в общем виде и повторно использовать в разных сценариях обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "g2i37mixtk9kkxkki1y8",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:34.362540Z",
     "iopub.status.busy": "2025-06-02T00:05:34.362361Z",
     "iopub.status.idle": "2025-06-02T00:05:39.600453Z",
     "shell.execute_reply": "2025-06-02T00:05:39.599826Z",
     "shell.execute_reply.started": "2025-06-02T00:05:34.362524Z"
    },
    "id": "rS_-00tYDMoB",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our main computing device is 'cpu'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "\n",
    "def get_computing_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = get_computing_device()\n",
    "print(f\"Our main computing device is '{device}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data loader and data augmentation\n",
    "Обычно для манипулирования данными используются две связанные абстракции:\n",
    "- Dataset (`torch.utils.data.Dataset` и его подклассы из `torchvision.datasets\") - некоторый черный ящик, который хранит и предварительно обрабатывает отдельные элементы dataset. В частности, на этом уровне обычно находятся дополнения для отдельных образцов.\n",
    "- DataLoader (`torch.utils.data.DataLoader`) - структура, объединяющая отдельные элементы в пакетном режиме.\n",
    "\n",
    "Давайте разберемся с обучающим набором данных. Вот несколько простых дополнений, которые мы собираемся использовать в наших экспериментах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:39.602128Z",
     "iopub.status.busy": "2025-06-02T00:05:39.601845Z",
     "iopub.status.idle": "2025-06-02T00:05:39.606320Z",
     "shell.execute_reply": "2025-06-02T00:05:39.605602Z",
     "shell.execute_reply.started": "2025-06-02T00:05:39.602110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_trainsforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(0.5, 0.5, 0.5),\n",
    "    transforms.RandomGrayscale(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для набора обучающих данных мы будем использовать пользовательский набор данных, который будет хранить все обучающие данные в оперативной памяти. Если у вас недостаточно оперативной памяти, вы можете использовать `torch vision.datasets.ImageFolder()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jrzsbgniodgtg1hif324k9",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:39.607591Z",
     "iopub.status.busy": "2025-06-02T00:05:39.607113Z",
     "iopub.status.idle": "2025-06-02T00:05:39.826802Z",
     "shell.execute_reply": "2025-06-02T00:05:39.826082Z",
     "shell.execute_reply.started": "2025-06-02T00:05:39.607572Z"
    },
    "id": "5vq5Cm0ADMoK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=train_trainsforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверка. Взгляните на папку `tiny-imagenet-200/val` и сравните ее с папкой `tiny-imagenet-200/train`. Выглядит по-другому, не так ли? Таким образом, мы не можем использовать `TinyImagenetRAM` для загрузки набора данных для проверки. Давайте вместо этого напишем пользовательский набор данных, но с таким же поведением, как у `TinyImagenetRAM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:39.827890Z",
     "iopub.status.busy": "2025-06-02T00:05:39.827623Z",
     "iopub.status.idle": "2025-06-02T00:05:40.119618Z",
     "shell.execute_reply": "2025-06-02T00:05:40.118959Z",
     "shell.execute_reply.started": "2025-06-02T00:05:39.827858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class TinyImagenetValDataset(Dataset):\n",
    "    def __init__(self, root, transform=transforms.ToTensor()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        with open(os.path.join(root, 'val_annotations.txt')) as f:\n",
    "            annotations = []\n",
    "            for line in f:\n",
    "                img_name, class_label = line.split('\\t')[:2]\n",
    "                annotations.append((img_name, class_label))\n",
    "\n",
    "        self.classes = sorted(list(set([label for _, label in annotations])))\n",
    "        \n",
    "        assert len(self.classes) == 200, len(self.classes)\n",
    "        assert all(self.classes[i] < self.classes[i+1] for i in range(len(self.classes)-1)), 'classes should be ordered'\n",
    "        assert all(isinstance(elem, type(annotations[0][1])) for elem in self.classes), 'your just need to reuse class_labels'\n",
    "\n",
    "        self.class_to_idx = {item: index for index, item in enumerate(self.classes)}\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images, self.targets = [], []\n",
    "        for img_name, class_name in tqdm.tqdm(annotations, desc=root):\n",
    "            img_name = os.path.join(root, 'images', img_name)\n",
    "\n",
    "            image = self.read_rgb_image(img_name)\n",
    "            \n",
    "            assert image.shape == (64, 64, 3), image.shape\n",
    "            self.images.append(Image.fromarray(image))\n",
    "            self.targets.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.images[index]\n",
    "        image = self.transform(image)\n",
    "        target = self.targets[index]\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    @staticmethod\n",
    "    def read_rgb_image(path_to_image):\n",
    "        image = cv2.imread(path_to_image)\n",
    "        return  cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте, наконец, загрузим набор данных для проверки. Обычно вам не применять аугментации для проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:40.120698Z",
     "iopub.status.busy": "2025-06-02T00:05:40.120394Z",
     "iopub.status.idle": "2025-06-02T00:05:41.302163Z",
     "shell.execute_reply": "2025-06-02T00:05:41.301494Z",
     "shell.execute_reply.started": "2025-06-02T00:05:40.120678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tiny-imagenet-200/val: 100%|██████████| 10000/10000 [00:55<00:00, 179.45it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = TinyImagenetValDataset('tiny-imagenet-200/val', transform=transforms.ToTensor())\n",
    "\n",
    "assert all(train_dataset.classes[i] == val_dataset.classes[i] for i in range(200)), \\\n",
    "    'class order in train and val datasets should be the same'\n",
    "assert all(train_dataset.class_to_idx[elem] == val_dataset.class_to_idx[elem] for elem in train_dataset.classes), \\\n",
    "    'class indices should be the same'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для большинства случаев будет достаточно `DataLoader` по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "6md8io0fesfby4r9per3jb",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.303319Z",
     "iopub.status.busy": "2025-06-02T00:05:41.302957Z",
     "iopub.status.idle": "2025-06-02T00:05:41.307289Z",
     "shell.execute_reply": "2025-06-02T00:05:41.306651Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.303277Z"
    },
    "id": "tY6OUeOODMoN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "hsq566ut87vokpkiq68",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.308111Z",
     "iopub.status.busy": "2025-06-02T00:05:41.307946Z",
     "iopub.status.idle": "2025-06-02T00:05:41.321707Z",
     "shell.execute_reply": "2025-06-02T00:05:41.321190Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.308098Z"
    },
    "id": "HBgW-gzwDMoQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "fxzxgbl11g2dixss4t9nx",
    "id": "arxSyhBLDMoX"
   },
   "source": [
    "### 1.2 Определение нейронной сети\n",
    "\n",
    "\"Сеть, подобная VGG\", обычно означает, что сеть представляет собой последовательность сверток с MaxPooling для понижающей размерности. Вот таблица из оригинальной статьи [\"Very Deep Convolutional Networks for Large-Scale Image Recognition\"].(https://arxiv.org/abs/1409.1556), который описывает классические конфигурации сетей VGG (часто называемые VGG-A, VGG-B и т.д. С использованием имени столбца в качестве идентификатора или VGG16, VGG19 и т.д. с использованием количества слоев в качестве идентификатора).\n",
    "\n",
    "![image.png](https://pytorch.org/assets/images/vgg.png)\n",
    "\n",
    "Эти сетевые конфигурации были разработаны для набора данных ImageNet. Поскольку изображения в tiny-imagenet имеют пониженный размер в 4 раза, мы собираемся разработать нашу собственную конфигурацию, уменьшив: \n",
    "1) количество слоев;\n",
    "2) количество нейронов в слоях;\n",
    "3) количество слоев с максимальным объединением, которые уменьшают выборку карт объектов\n",
    "\n",
    "Конфигурация нашей сети будет выглядеть следующим образом [Conv(16), Conv(16), MaxPool] + [Conv(32), Conv(32), MaxPool] + [Conv(64), Conv(64), MaxPool] + [Conv(128), Conv(128)] + [GlobalAveragePooling] + [FC(200) + softmax]\n",
    "\n",
    "\n",
    "Мы используем Conv(128) и GlobalAveragePooling вместо image flattening и слоев FC для уменьшения количества параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "g5yf9z66xdpvq688ze2d8",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.324072Z",
     "iopub.status.busy": "2025-06-02T00:05:41.323641Z",
     "iopub.status.idle": "2025-06-02T00:05:41.336681Z",
     "shell.execute_reply": "2025-06-02T00:05:41.335867Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.324054Z"
    },
    "id": "7QF2hMVxDMoY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6yn15hpuolcmryork2oqs",
    "id": "DJ6QKG3hDMoa"
   },
   "source": [
    "И еще кое-что. VGG был разработан до того, как был придуман BatchNormalization. В настоящее время было бы глупо, если бы мы не использовали BatchNormalization в нашей сети. Итак, давайте определим простой модуль, содержащий свертку, BatchNormalization и relu, и построим нашу сеть, используя этот модуль. Вот также реализация GlobalAveragePooling, приведенная для вас в качестве примера пользовательского модуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "f985tf2dvssqwmyc6w99d",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.337494Z",
     "iopub.status.busy": "2025-06-02T00:05:41.337294Z",
     "iopub.status.idle": "2025-06-02T00:05:41.346745Z",
     "shell.execute_reply": "2025-06-02T00:05:41.346011Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.337481Z"
    },
    "id": "u_mbfRXMDMob",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class GlobalAveragePool(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    def forward(self, x):\n",
    "        return torch.mean(x, dim=self.dim)\n",
    "\n",
    "    \n",
    "class ConvBNRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding='same'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def create_vgg_like_network(config=None):\n",
    "    \"\"\"\n",
    "    Creates VGG like network according to config\n",
    "    \"\"\"\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    default_config = [[16,16], [32, 32], [64, 64], [128, 128]]\n",
    "    config = config or default_config\n",
    "    \n",
    "    in_channels = 3\n",
    "    for block_index in range(len(config)):\n",
    "        for layer_index_in_block in range(len(config[block_index])):\n",
    "            out_channels = config[block_index][layer_index_in_block]\n",
    "            \n",
    "            model.add_module(f\"conv_{block_index}_{layer_index_in_block}\", ConvBNRelu(in_channels, out_channels, 3))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        if block_index != len(config) - 1:\n",
    "            model.add_module(f'mp_{block_index}', nn.MaxPool2d(3, stride=2))\n",
    "            \n",
    "    model.add_module('pool', GlobalAveragePool(dim=(2,3)))\n",
    "    model.add_module('logits', nn.Linear(out_channels, 200))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот и создана наша модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.347622Z",
     "iopub.status.busy": "2025-06-02T00:05:41.347434Z",
     "iopub.status.idle": "2025-06-02T00:05:41.567122Z",
     "shell.execute_reply": "2025-06-02T00:05:41.566573Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.347608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = create_vgg_like_network()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7dh3d8xmkeinv4kx0g079",
    "id": "DvugZZbeDMoe"
   },
   "source": [
    "### 1.3 Определение функции потерь\n",
    "\n",
    "Обычно в качестве функции потерь для классификации изображений используется cross-entropy (отрицательное логарифмическое правдоподобие)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "3y7p7o6s7vecpf3kpktj8v",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.568107Z",
     "iopub.status.busy": "2025-06-02T00:05:41.567854Z",
     "iopub.status.idle": "2025-06-02T00:05:41.571668Z",
     "shell.execute_reply": "2025-06-02T00:05:41.571015Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.568081Z"
    },
    "id": "cGEhRWMYDMof",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(predictions, gt):\n",
    "    return F.cross_entropy(predictions, gt).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Optimizer and training schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим нашу сеть, используя Adam с параметрами по умолчанию. \n",
    "\n",
    "Для обучения с помощью `torch.optim.SGD` вам обычно нужно определить training schedule - способ, как снизить learning rate во время тренировки. Но поскольку в adam все градиенты масштабируются по моменту, эффект от правильного графика тренировок не так важен для обучения, как в SGD. Поэтому мы будем действовать как ленивые специалисты по обработке данных и не будем использовать шедулер вообще. Но вы можете поиграть с шедулером, используя, например, `torch.optim.lr_scheduler.ExponentialLR`, смотрите [документацию](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) с объяснением, как это использовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.572611Z",
     "iopub.status.busy": "2025-06-02T00:05:41.572393Z",
     "iopub.status.idle": "2025-06-02T00:05:41.586291Z",
     "shell.execute_reply": "2025-06-02T00:05:41.585632Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.572589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Цикл обучения\n",
    "\n",
    "Давайте объединим ранее определенные элементы вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "w8rht9ygh7uns89ypozln",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:48.894261Z",
     "iopub.status.busy": "2025-06-02T00:05:48.893988Z",
     "iopub.status.idle": "2025-06-02T00:05:48.901558Z",
     "shell.execute_reply": "2025-06-02T00:05:48.901007Z",
     "shell.execute_reply.started": "2025-06-02T00:05:48.894240Z"
    },
    "id": "sEy0LiHxDMol",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def eval_model(model, data_generator):\n",
    "    accuracy = []\n",
    "    model.train(False) \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_generator:\n",
    "            X_batch = X_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            y_pred = logits.max(1)[1].data\n",
    "            accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "            \n",
    "def train_model(model, optimizer, train_data_generator):\n",
    "    train_loss = []\n",
    "    model.train(True) \n",
    "    for (X_batch, y_batch) in tqdm.tqdm(train_data_generator):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        predictions = model(X_batch)\n",
    "        loss = compute_loss(predictions, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def train_loop(model, optimizer, train_data_generator, val_data_generator, num_epochs):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss = train_model(model, optimizer, train_data_generator)\n",
    "        \n",
    "        val_accuracy = eval_model(model, val_data_generator)\n",
    "\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Обучение\n",
    "\n",
    "Вся подготовка завершена, пора запускать обучение!\n",
    "\n",
    "Обычно после обучения в течение 30 эпох вы должны получить нейронную сеть, которая предсказывает метки с точностью более 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T10:09:18.807666Z",
     "iopub.status.busy": "2025-06-01T10:09:18.806977Z",
     "iopub.status.idle": "2025-06-01T10:43:54.158686Z",
     "shell.execute_reply": "2025-06-01T10:43:54.157892Z",
     "shell.execute_reply.started": "2025-06-01T10:09:18.807636Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [06:05<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Say Hello to ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вам нужно переопределить вашу модель, все остальное останется прежним. Как и в случае с VGG, мы собираемся определить модель, подобную ResNet, а не классическую архитектуру, разработанную для классификации ImageNet.\n",
    "\n",
    "\"ResNet-подобный\" обычно означает, что ваша сеть состоит из \"residual блоков\". Существует два широко используемых типа блоков: с двумя и с тремя свертками:\n",
    "![resnet_blocks](https://miro.medium.com/max/613/1*zS2ChIMwAqC5DQbL5yD9iQ.png)\n",
    "\n",
    "На практике часто используются блоки с тремя свертками, поскольку они позволяют построить более глубокую сеть с меньшими параметрами. Блоки с двумя свертками обычно используются для сравнения с non-residual сетями, особенно с VGG и AlexNet.\n",
    "\n",
    "Вот таблица из статьи \"[Deep Residual Learning for Image Recognition]\"(https://arxiv.org/pdf/1512.03385.pdf), в которой описываются классические конфигурации сетей ResNet. Обычно их называют ResNet-18, ResNet-34 и так далее, используя количество слоев в качестве идентификатора. Обратите внимание, что сети, начиная с ResNet-50, основаны на 3-сверточных блоках. На самом деле ResNet-18 и ResNet-34 были представлены только для сравнения с VGG, в то время как ResNet-50 обычно используется на практике в качестве хорошего бейслайна.\n",
    "\n",
    "![изображение](https://miro.medium.com/max/2400/1*aq0q7gCvuNUqnMHh4cpnIw.png)\n",
    "\n",
    "Как и в случае с VGG, мы собираемся создать нашу собственную конфигурацию для сети. Давайте используем 2-сверточных блока для сравнения с vgg и возьмем сеть типа [Conv7x7 - 32] + [conv32-block, conv32-block] + [conv64-block, conv64-block] + [conv128-block, conv128-block] + [GlobalAveragePooling] + fc200 + softmax\n",
    "\n",
    "По сравнению с ResNet18, мы уменьшили количество фильтров и убрали max-pooling в начале и в последнем наборе сверток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:55.796677Z",
     "iopub.status.busy": "2025-06-02T00:05:55.796127Z",
     "iopub.status.idle": "2025-06-02T00:05:55.804652Z",
     "shell.execute_reply": "2025-06-02T00:05:55.803816Z",
     "shell.execute_reply.started": "2025-06-02T00:05:55.796652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNetBlock2(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = None \n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, 1, stride, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = self.conv1(x)\n",
    "        residual = self.bn1(residual)\n",
    "        residual = self.relu1(residual)\n",
    "        residual = self.conv2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "\n",
    "        if self.conv3 is not None:\n",
    "            x = self.conv3(x)\n",
    "\n",
    "        result = self.relu2(residual + x)\n",
    "        return result\n",
    "\n",
    "def create_resnet_like_network():\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    config = [[32, 32], [64, 64], [128, 128]]\n",
    "    model.add_module('init_conv', ConvBNRelu(3, 32, kernel_size=7, stride=2, padding=3))\n",
    "    \n",
    "    in_channels = 32\n",
    "    for i in range(len(config)):\n",
    "        for j in range(len(config[i])):\n",
    "            out_channels = config[i][j]\n",
    "            stride = 2 if i != 0 and j == 0 else 1\n",
    "\n",
    "            model.add_module(f\"resnet_{i}_{j}\", ResNetBlock2(in_channels, out_channels))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "    model.add_module('pool', GlobalAveragePool((2,3)))\n",
    "    model.add_module('logits', nn.Linear(out_channels, 200))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда давайте потренируем нашу сеть. Обычно после обучения в течение 30 эпох вы должны получить нейронную сеть, которая предсказывает метки с точностью >40% и дает около +1% профита по сравнению с vgg, из предыдущего эксперимента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T12:05:20.660422Z",
     "iopub.status.busy": "2025-06-01T12:05:20.659708Z",
     "iopub.status.idle": "2025-06-01T13:08:54.259448Z",
     "shell.execute_reply": "2025-06-01T13:08:54.258595Z",
     "shell.execute_reply.started": "2025-06-01T12:05:20.660399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = create_resnet_like_network().to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы внимательно изучали нашу сеть resnet, то могли заметить, что она имеет почти в 2 раза больше параметров и в 2 раза глубже, чем vgg. Давайте определим сеть, сопоставимую vgg, удвоив количество уровней conv.\n",
    "\n",
    "Наш новый сайт VGG-как архитектура будет [Сопу(16), усл. (16), MaxPool] + [Сопу(32), П(32), П(32), П(32), MaxPool] + [Сопу(64) отн(64) отн(64) отн(64), MaxPool] + [Сопу(128), Сопу(128), Сопу(128), Сопу(128)] + [GlobalAveragePooling] + [ФК(200) + softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:06:08.337080Z",
     "iopub.status.busy": "2025-06-02T00:06:08.336805Z",
     "iopub.status.idle": "2025-06-02T00:42:41.271034Z",
     "shell.execute_reply": "2025-06-02T00:42:41.270213Z",
     "shell.execute_reply.started": "2025-06-02T00:06:08.337059Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = create_vgg_like_network(config=[[16,16], [32,32,32,32], [64, 64, 64, 64], [128, 128, 128, 128]])\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видите ли вы выгоду от residual связей? \n",
    "\n",
    "Качество сети vgg в этом эксперименте может быть даже хуже, чем качество сети vgg в первом эксперименте. Это связано с проблемой затухания градиента, которая затрудняет обучение глубоких нейронных сетей без residual связей."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "seminar_pytorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "notebookId": "0bd81ca7-4175-4905-a84c-21ed8da72299"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
